The program comes with a built in demo in the form of "gpu_demo". It will prompt you for a file path. The first line of that file path should be the regex and then the rest of the file should be the gpu you want to match. It will first run the CPU regex, and it will give you the time to run the matching. It will then prompt you for the number of blocks and threads you'd like to use for the regex matching. It will then run the matching for the GPU engine. 

This program does regex matching! It returns all occurences matching a particular regex within a text file. Its purpose is to be used on very large text with very complicated regex so that it can go very fast. We model a Non Determenistic Finite Automata to serve as our regex engine. 

NOTES ABOUT THE REGEX: This regex is kind of limited. For example: There is no anchoring characters! So you can't specify the start or end string using '$' or '^'. There is also no look ahead. The operators you can use are: union, given by '|', kleene star given by '*', '+' which is the kleene star but you require that you match one, '?' which is match one or zero times, and explicit concatenation is given by '@' (though the parser will explicilty compute concatenations like normal regex engines do). You can also use "wild card" characters using the '.' character. So '.' will match with anything.  


The core of the implementation is that we represent the regex as a 'non determenistic finite automata' like from CS21. To compute regex matching for an entire string, you essentially need to see wether the regex matches with every possible suffix of the string. So the way our parallelism works, is that we represnt a 'state_vector' which has columns being defined as the states of the NFA, and rows being defined as suffixes of the string. Each block has a range of suffixes that it is responsible for. To prevent warp divergences we use syncwarps to ensure that the hard computation only begins once each thread has found an element of the state vec that corresponds to an active state in the NFA. This implementation unfortunately has pretty bad coalesence properties. The only accesses that are usually decently coalesced are the string accesses for the string we're trying to match the regex with.  

To help me understand the structure of the NFA I actually built a visualizer using graphviz. Titan doesn't have graphviz installed so the visualizer won't run on this implementation, but I included an NFA diagram example: "hello_world_regex_diagram.png". This diagram corresponds to the regex "(he|llo)wor@(ld)*". I also included a diagram "many_unions_regex_diagram.png" which shows the regex "(cat|shell|gold|tiger|beta)@( fish)". This diagram really illustrates the very large amount of redundant states created by my current parser. 

For judging the performance. The GPU runs about 3 times faster matching simple regexes over shakespeare's sonnets then the CPU version. However that's about the only good thing about the GPU version. First off if the regexes get more complicated then the memory requirements for the gpu version become too large to sustain. Like we're using shared memory to store the representation of the state vector and so very large NFAs just won't fit. 
Another issue is that there is undefined behavior for trying to use any number of threads outside of 32. I think this might have to do with the use of 'syncwarps'. 

I think If I had had more time there was a lot I could do to improve this. Firstly I'd get the GPU implementation to be more consistent (it sometimes misses matches or double matches). I also think I could get a big speed up by reducing the number of states in my NFA. Getting good coalescing also ended up being basically impossible, since the tasks for each thread were so disjoint and input dependent. I also really want to figure out exactly what is causing the issue of undefined behavior on larger amount of threads then 32 (probably worth it to try and replace __syncwarps with something like ballot sync? Ideally I wouldn't need to sync in the first place but alas). However I think I did a good job avoiding extremely long warp divergences, and in general more threads leads to faster performance. 

Overall this was a very fun project and I truly learned a TON about GPU programming from it! Thank you so much for giving me the opportunity to learn! 